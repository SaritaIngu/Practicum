{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading all the files (stop words, negative and positive words into 3 different dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shikh\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['text']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "\n",
    "import sklearn as sk\n",
    "import sklearn.tree as tree\n",
    "from IPython.display import Image  \n",
    "\n",
    "import bs4 as bs\n",
    "import csv\n",
    "import requests\n",
    "import urllib\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloomberg: Apple loses key execs in India strugglesJul. 16, 2018 8:05 AM ET|About: Apple Inc. (AAPL)|By: Brandy Betz, SA News EditorApple (NASDAQ:AAPL) has lost three execs in India in recent weeks, according to Bloomberg sources.The departures include the national sales and distribution chief, the commercial channels and mid-market business head, and the leader of telecom carrier sales.Apple has struggled to gain traction in India due to high import tariffs and a consumer base that prefers cheaper smartphones. Apple has a single-digit market share in the country.Sources say Apple has been slow to cultivate local business relationships and has had difficulties understanding the market.Michel Coulomb took over as head of Indian operations last December. Coulomb has been with Apple since 2003 and was previously the South Asia managing director.Apple shares are up 0.2% premarket to $191.65.Previously: Apple roundup: Production starts on iPhone 6s in India, Barclays forecasts June Q (June 26)\n"
     ]
    }
   ],
   "source": [
    "text=''\n",
    "with open(\"C:\\\\Users\\\\shikh\\\\Desktop\\\\Practicum\\\\Apple_India.txt\",\"r\") as apple_text:\n",
    "    for line in apple_text:                         \n",
    "        line = line.strip()\n",
    "        text += line\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facebook -20% on guidance for slowing revenue growthJul. 25, 2018 5:40 PM ET|About: Facebook (FB)|By: Jason Aycock, SA News EditorFacebook's (NASDAQ:FB) slide has turned into a dive after hours, with shares now down 20% on millions of shares traded, after the conference call reveals guidance for dropping revenue growth rates.The company says it sees growth rate dropping by high single digits for the next couple of quarters.Total expense growth will exceed revenue growth in 2019, the company says.Share fell in the immediate aftermath of the company's Q2 report, where profits beat expectations but revenues missed and some observers had hoped for higher monthly active users (actual report: 2.23B).\n"
     ]
    }
   ],
   "source": [
    "fb_text1=''\n",
    "with open(\"C:\\\\Users\\\\shikh\\\\Desktop\\\\Practicum\\\\facebook_slowingrevenue.txt\",\"r\") as apple_text:\n",
    "    for line in apple_text:                         \n",
    "        line = line.strip()\n",
    "        fb_text1 += line\n",
    "print(fb_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYT: China withdraws approval for Facebook unitJul. 25, 2018 10:17 AM ET|About: Facebook (FB)|By: Jason Aycock, SA News EditorChina has quickly pulled approval for Facebook (NASDAQ:FB) to open a local subsidiary, The New York Times reports.A database that showed the approval has seen the registration disappear, and references to the subsidiary have been partially censored in Chinese media -- and now that approval has been withdrawn, according to the report.The removal comes amid a disagreement between provincial officials in Zhejiang (where Facebook's local unit was to be set) and the Cyberspace Administration of China.Previously: Facebook sets up Chinese subsidiary (Jul. 24 2018)Visit Seeking Alpha's Premium ETF Screener, the best ETF research tool for your portfolio\n"
     ]
    }
   ],
   "source": [
    "fb_text2=''\n",
    "with open(\"C:\\\\Users\\\\shikh\\\\Desktop\\\\Practicum\\\\fb_china.txt\",\"r\") as apple_text:\n",
    "    for line in apple_text:                         \n",
    "        line = line.strip()\n",
    "        fb_text2 += line\n",
    "print(fb_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading stop words into stop_words dictionary\n",
    "\n",
    "stop_words={}\n",
    "with open(\"C:\\\\Users\\\\shikh\\\\Desktop\\\\Practicum\\\\stop_words.txt\",'r') as sw:    ##opening stop_words.txt file\n",
    "    for line in sw:                        \n",
    "        line =line.strip()               ##stripping any blank spaces from the beginning & end of line\n",
    "        stop_words[line] = 0             ## Entering the word to stop_words dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading negative words into negative_words dictionary\n",
    "negative_words={}\n",
    "with open(\"C:\\\\Users\\\\shikh\\\\Desktop\\\\Practicum\\\\negative-words.txt\",'r') as nw:          ##opening negative_words.txt file\n",
    "    for line in nw:\n",
    "        line = line.strip()                         ##stripping any blank spaces from the beginning & end of line\n",
    "        negative_words[line] = 0                     ## Entering the word to negative_words dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading negative words into positive_words dictionary\n",
    "positive_words={}\n",
    "with open(\"C:\\\\Users\\\\shikh\\\\Desktop\\\\Practicum\\\\positive-words.txt\",'r') as pw:   ##opening postive_words.txt file\n",
    "    for line in pw:\n",
    "        line = line.strip()                  ##stripping any blank spaces from the beginning & end of line\n",
    "        positive_words[line] = 0             ## Entering the word to postive_words dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "4783\n",
      "2007\n"
     ]
    }
   ],
   "source": [
    "# Check if words have been loaded or not\n",
    "print(len(stop_words))                  \n",
    "print(len(negative_words))\n",
    "print(len(positive_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyt:\n",
      "china\n",
      "withdraws\n",
      "approval\n",
      "+\n",
      "for\n",
      "facebook\n",
      "unit\n",
      "jul.\n",
      "25,\n",
      "2018\n",
      "10:17\n",
      "am\n",
      "et|about:\n",
      "facebook\n",
      "fb|by:\n",
      "jason\n",
      "aycock,\n",
      "sa\n",
      "news\n",
      "editor\n",
      "china\n",
      "has\n",
      "quickly\n",
      "pulled\n",
      "approval\n",
      "+\n",
      "for\n",
      "facebook\n",
      "nasdaq:fb\n",
      "to\n",
      "open\n",
      "a\n",
      "local\n",
      "subsidiary,\n",
      "the\n",
      "new\n",
      "york\n",
      "times\n",
      "reports.\n",
      "a\n",
      "database\n",
      "that\n",
      "showed\n",
      "the\n",
      "approval\n",
      "+\n",
      "has\n",
      "seen\n",
      "the\n",
      "registration\n",
      "disappear,\n",
      "and\n",
      "references\n",
      "to\n",
      "the\n",
      "subsidiary\n",
      "have\n",
      "been\n",
      "partially\n",
      "censored\n",
      "in\n",
      "chinese\n",
      "media\n",
      "\n",
      "and\n",
      "now\n",
      "that\n",
      "approval\n",
      "+\n",
      "has\n",
      "been\n",
      "withdrawn,\n",
      "according\n",
      "to\n",
      "the\n",
      "report.\n",
      "the\n",
      "removal\n",
      "comes\n",
      "amid\n",
      "a\n",
      "disagreement\n",
      "-\n",
      "between\n",
      "provincial\n",
      "officials\n",
      "in\n",
      "zhejiang\n",
      "where\n",
      "facebook's\n",
      "local\n",
      "unit\n",
      "was\n",
      "to\n",
      "be\n",
      "set\n",
      "and\n",
      "the\n",
      "cyberspace\n",
      "administration\n",
      "of\n",
      "china.\n",
      "previously:\n",
      "facebook\n",
      "sets\n",
      "up\n",
      "chinese\n",
      "subsidiary\n",
      "jul.\n",
      "24\n",
      "2018\n",
      "visit\n",
      "seeking\n",
      "alpha's\n",
      "premium\n",
      "etf\n",
      "screener,\n",
      "the\n",
      "best\n",
      "+\n",
      "etf\n",
      "research\n",
      "tool\n",
      "for\n",
      "your\n",
      "portfolio\n",
      "POSITIVE COUNT:5\n",
      "NEGATIVE COUNT:-1\n",
      "SUM IS:4\n"
     ]
    }
   ],
   "source": [
    "# Read the  file and identify number of positive and negative words while taking care of stop words\n",
    "positive_sentiment=0\n",
    "negative_sentiment=0\n",
    "##defining clean(word) function for the purpose of removing special characters\n",
    "def clean(word):\n",
    "    symbols = ['!','@','#','$','%','_','^','&','*','(',')','-','+','=','?']\n",
    "    for symbol in symbols:\n",
    "        word = word.replace(symbol,'')\n",
    "    return word\n",
    "\n",
    "with open(\"C:\\\\Users\\\\shikh\\\\Desktop\\\\Practicum\\\\fb_china.txt\",'r') as tweets:            ###opening original tweet file\n",
    "    for line in tweets:                         \n",
    "        line = line.strip()                       ##stripping characters before and after the line\n",
    "        words = line.split()                      ## getting words from  the lines\n",
    "        for word in words:\n",
    "            word = word.lower()                 ##getting lower case of the word\n",
    "            word = clean(word)                  ##applying clean function to the words\n",
    "            print(word)\n",
    "            if word not in stop_words:          ##check if word  is not in stop_words dictionary\n",
    "                if word in positive_words:      ## check if the word is in positive_words dictionary \n",
    "                    print('+')\n",
    "                    positive_sentiment = positive_sentiment +1       ###if yes add 1 to count of positive_tweets\n",
    "                elif word in negative_words:                    ##if no checck if the words is in negative_words dictionary\n",
    "                    negative_sentiment = negative_sentiment -1        ## if yes substract 1 from the count of negative_tweets\n",
    "                    print('-')\n",
    "                    \n",
    "##concatenating string POSITIVE COUNT:with string of positive_tweets\n",
    "print(\"POSITIVE COUNT:\" + str(positive_sentiment))  \n",
    "##concatenating string NEGATIVE COUNT:with string of negative_tweets\n",
    "print(\"NEGATIVE COUNT:\" + str(negative_sentiment))           \n",
    "\n",
    "# Concatening and printing sum of positive and negative tweets:\n",
    "\n",
    "print(\"SUM IS:\" + str(positive_sentiment+negative_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook\n",
      "20\n",
      "on\n",
      "guidance\n",
      "+\n",
      "for\n",
      "slowing\n",
      "revenue\n",
      "growth\n",
      "jul.\n",
      "25,\n",
      "2018\n",
      "5:40\n",
      "pm\n",
      "et|about:\n",
      "facebook\n",
      "fb|by:\n",
      "jason\n",
      "aycock,\n",
      "sa\n",
      "news\n",
      "editor\n",
      "facebook's\n",
      "nasdaq:fb\n",
      "slide\n",
      "has\n",
      "turned\n",
      "into\n",
      "a\n",
      "dive\n",
      "after\n",
      "hours,\n",
      "with\n",
      "shares\n",
      "now\n",
      "down\n",
      "20\n",
      "on\n",
      "millions\n",
      "of\n",
      "shares\n",
      "traded,\n",
      "after\n",
      "the\n",
      "conference\n",
      "call\n",
      "reveals\n",
      "guidance\n",
      "+\n",
      "for\n",
      "dropping\n",
      "revenue\n",
      "growth\n",
      "rates.\n",
      "the\n",
      "company\n",
      "says\n",
      "it\n",
      "sees\n",
      "growth\n",
      "rate\n",
      "dropping\n",
      "by\n",
      "high\n",
      "single\n",
      "digits\n",
      "for\n",
      "the\n",
      "next\n",
      "couple\n",
      "of\n",
      "quarters.\n",
      "total\n",
      "expense\n",
      "growth\n",
      "will\n",
      "exceed\n",
      "+\n",
      "revenue\n",
      "growth\n",
      "in\n",
      "2019,\n",
      "the\n",
      "company\n",
      "says.\n",
      "share\n",
      "fell\n",
      "-\n",
      "in\n",
      "the\n",
      "immediate\n",
      "aftermath\n",
      "of\n",
      "the\n",
      "company's\n",
      "q2\n",
      "report,\n",
      "where\n",
      "profits\n",
      "beat\n",
      "expectations\n",
      "but\n",
      "revenues\n",
      "missed\n",
      "-\n",
      "and\n",
      "some\n",
      "observers\n",
      "had\n",
      "hoped\n",
      "for\n",
      "higher\n",
      "monthly\n",
      "active\n",
      "users\n",
      "actual\n",
      "report:\n",
      "2.23b.\n",
      "POSITIVE COUNT:3\n",
      "NEGATIVE COUNT:-2\n",
      "SUM IS:1\n"
     ]
    }
   ],
   "source": [
    "# Read the  file and identify number of positive and negative words while taking care of stop words\n",
    "positive_sentiment=0\n",
    "negative_sentiment=0\n",
    "##defining clean(word) function for the purpose of removing special characters\n",
    "def clean(word):\n",
    "    symbols = ['!','@','#','$','%','_','^','&','*','(',')','-','+','=','?']\n",
    "    for symbol in symbols:\n",
    "        word = word.replace(symbol,'')\n",
    "    return word\n",
    "\n",
    "with open(\"C:\\\\Users\\\\shikh\\\\Desktop\\\\Practicum\\\\facebook_slowingrevenue.txt\",'r') as tweets:            ###opening original tweet file\n",
    "    for line in tweets:                         \n",
    "        line = line.strip()                       ##stripping characters before and after the line\n",
    "        words = line.split()                      ## getting words from  the lines\n",
    "        for word in words:\n",
    "            word = word.lower()                 ##getting lower case of the word\n",
    "            word = clean(word)                  ##applying clean function to the words\n",
    "            print(word)\n",
    "            if word not in stop_words:          ##check if word  is not in stop_words dictionary\n",
    "                if word in positive_words:      ## check if the word is in positive_words dictionary \n",
    "                    print('+')\n",
    "                    positive_sentiment = positive_sentiment +1       ###if yes add 1 to count of positive_tweets\n",
    "                elif word in negative_words:                    ##if no checck if the words is in negative_words dictionary\n",
    "                    negative_sentiment = negative_sentiment -1        ## if yes substract 1 from the count of negative_tweets\n",
    "                    print('-')\n",
    "                    \n",
    "##concatenating string POSITIVE COUNT:with string of positive_tweets\n",
    "print(\"POSITIVE COUNT:\" + str(positive_sentiment))  \n",
    "##concatenating string NEGATIVE COUNT:with string of negative_tweets\n",
    "print(\"NEGATIVE COUNT:\" + str(negative_sentiment))           \n",
    "\n",
    "# Concatening and printing sum of positive and negative tweets:\n",
    "\n",
    "print(\"SUM IS:\" + str(positive_sentiment+negative_sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis  with TextBlob and VADER Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TextBlob is a Python (2 and 3) library for processing textual data. \n",
    "##It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
    "\n",
    "\n",
    "##VADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to \n",
    "##sentiments expressed in social media, and works well on texts from other domains.\n",
    "\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis1=TextBlob(fb_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analysis2 = TextBlob(fb_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With TextBlob, we get a polarity and a subjectivity metric.* The polarity is the sentiment itself, ranging from a -1 to a +1. The subjectivity is a measure of the sentiment being objective to subjective, and goes from 0 to 1. We'd rather see sentiment that is objective than subjective, so a lower score should likely denote a more likely-to-be-accurate reading. We'll see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0070975056689342375, subjectivity=0.320453514739229)\n"
     ]
    }
   ],
   "source": [
    "print(analysis1.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.15218855218855218, subjectivity=0.2282828282828283)\n"
     ]
    }
   ],
   "source": [
    "print(analysis2.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vadersentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neg is negative sentiment found, neu is anything found to be neutral, pos is positive, and the compound is \"computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, then normalized... [it] is the most useful metric if you want a single unidimensional measure of sentiment.\" (from the docs). The docs also suggest:\n",
    "\n",
    "positive sentiment: compound score >= 0.5 neutral sentiment: (compound score > -0.5) and (compound score < 0.5) negative sentiment: compound score <= -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.024, 'neu': 0.814, 'pos': 0.162, 'compound': 0.91}\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vs = analyzer.polarity_scores(fb_text1)\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.047, 'neu': 0.823, 'pos': 0.13, 'compound': 0.9118}\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vs = analyzer.polarity_scores(fb_text2)\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
